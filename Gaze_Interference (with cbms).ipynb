{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9450482,"sourceType":"datasetVersion","datasetId":5744249},{"sourceId":9450776,"sourceType":"datasetVersion","datasetId":5744451},{"sourceId":9477280,"sourceType":"datasetVersion","datasetId":5764188},{"sourceId":10913948,"sourceType":"datasetVersion","datasetId":6784478},{"sourceId":11083033,"sourceType":"datasetVersion","datasetId":6907723},{"sourceId":256716,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":219439,"modelId":241193},{"sourceId":257024,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":219702,"modelId":241462},{"sourceId":311489,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":264188,"modelId":285283}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pydicom\n\nimport os\nimport shutil\nimport numpy as np\nimport pandas as pd \nimport cv2\nimport pydicom\nfrom PIL import Image\nimport timm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\nimport timm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nimport torchvision.transforms.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:56:05.080354Z","iopub.execute_input":"2025-04-05T10:56:05.080677Z","iopub.status.idle":"2025-04-05T10:56:21.493365Z","shell.execute_reply.started":"2025-04-05T10:56:05.080644Z","shell.execute_reply":"2025-04-05T10:56:21.492422Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Define directories for DICOM and heatmap images\n","metadata":{}},{"cell_type":"code","source":"dicom_dir = '/kaggle/input/dicom-files/dicom files'  \nheatmap_dir = '/kaggle/input/heatmap-images/heatmap_images'  \nfused_dir = '/kaggle/working/fused_images_kaggle'  \n\nos.makedirs(fused_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:56:26.805484Z","iopub.execute_input":"2025-04-05T10:56:26.805837Z","iopub.status.idle":"2025-04-05T10:56:26.810429Z","shell.execute_reply.started":"2025-04-05T10:56:26.805806Z","shell.execute_reply":"2025-04-05T10:56:26.808985Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Function to fuse dicoms and heatmaps","metadata":{}},{"cell_type":"code","source":"def fuse_images_with_resizing(dicom_image, heatmap_image):\n    '''\n    Function to fuse dicoms and heatmaps\n    '''\n    heatmap_resized = cv2.resize(heatmap_image, (dicom_image.shape[1], dicom_image.shape[0]))\n\n    heatmap_resized = (heatmap_resized - np.min(heatmap_resized)) / (np.max(heatmap_resized) - np.min(heatmap_resized))\n\n    fused_image = dicom_image * heatmap_resized\n    \n    return fused_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:56:50.931725Z","iopub.execute_input":"2025-04-05T10:56:50.932049Z","iopub.status.idle":"2025-04-05T10:56:50.936239Z","shell.execute_reply.started":"2025-04-05T10:56:50.932020Z","shell.execute_reply":"2025-04-05T10:56:50.935439Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Fusing dicoms and corresponding heatmaps","metadata":{}},{"cell_type":"code","source":"for dicom_filename in os.listdir(dicom_dir):\n    if dicom_filename.endswith('.dcm'):\n        dicom_path = os.path.join(dicom_dir, dicom_filename)\n        dicom_image = pydicom.dcmread(dicom_path).pixel_array\n\n        heatmap_filename = dicom_filename.replace('.dcm', '.png')\n        heatmap_path = os.path.join(heatmap_dir, heatmap_filename)\n\n        if os.path.exists(heatmap_path):\n            heatmap_image = cv2.imread(heatmap_path, cv2.IMREAD_GRAYSCALE)\n            fused_image = fuse_images_with_resizing(dicom_image, heatmap_image)\n            dicom_id = dicom_filename.replace('.dcm', '')  \n            fused_image_path = os.path.join(fused_dir, f\"{dicom_id}.png\")\n            cv2.imwrite(fused_image_path, fused_image)\n        else:\n            print(f\"Heatmap image not found for {dicom_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:56:52.530831Z","iopub.execute_input":"2025-04-05T10:56:52.531114Z","iopub.status.idle":"2025-04-05T11:03:09.206604Z","shell.execute_reply.started":"2025-04-05T10:56:52.531091Z","shell.execute_reply":"2025-04-05T11:03:09.205930Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Updating the csv file","metadata":{}},{"cell_type":"code","source":"csv_file = '/kaggle/input/labels-large/manually_made_large.csv'  \nupdated_csv_file = '/kaggle/working/updated_csv_file.csv'  \n\ndf = pd.read_csv(csv_file)\n\nfused_image_names = [os.path.splitext(f)[0] for f in os.listdir(fused_dir) if f.endswith('.png')]\n\ndf_filtered = df[df['fused_image_name'].isin(fused_image_names)]\n\ndf_filtered.to_csv(updated_csv_file, index=False)\n\nprint(f\"Updated CSV file saved at: {updated_csv_file}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:03:09.207624Z","iopub.execute_input":"2025-04-05T11:03:09.207847Z","iopub.status.idle":"2025-04-05T11:03:09.240522Z","shell.execute_reply.started":"2025-04-05T11:03:09.207828Z","shell.execute_reply":"2025-04-05T11:03:09.239919Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Updated CSV file saved at: /kaggle/working/updated_csv_file.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"csv_file_path = '/kaggle/working/updated_csv_file.csv'  \ndata_df = pd.read_csv(csv_file_path)\n\ndata_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:03:09.241783Z","iopub.execute_input":"2025-04-05T11:03:09.241982Z","iopub.status.idle":"2025-04-05T11:03:09.260514Z","shell.execute_reply.started":"2025-04-05T11:03:09.241963Z","shell.execute_reply":"2025-04-05T11:03:09.259674Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                               fused_image_name  label\n0  002da0d9-ce49c30d-4dfcc1f8-746d2401-d8044d48      0\n1  0066734a-35568fde-fd52ba23-ec66f3de-88d4aaf9      1\n2  00fe73b4-5215bb4f-94bbccc4-ac5f4f6f-52805cfb      1\n3  010fa20c-6ac04c8a-f6d4bc0b-eb1e735c-cd940793      2\n4  018680d4-8fb864f0-dffebf54-bcba02ab-9b601e7a      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fused_image_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>002da0d9-ce49c30d-4dfcc1f8-746d2401-d8044d48</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0066734a-35568fde-fd52ba23-ec66f3de-88d4aaf9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00fe73b4-5215bb4f-94bbccc4-ac5f4f6f-52805cfb</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>010fa20c-6ac04c8a-f6d4bc0b-eb1e735c-cd940793</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>018680d4-8fb864f0-dffebf54-bcba02ab-9b601e7a</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Define image transformations","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.RandomHorizontalFlip(p=0.5),  \n    transforms.RandomRotation(degrees=15),  \n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  \n    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),  \n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n    transforms.GaussianBlur(kernel_size=3),  \n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:03:09.261373Z","iopub.execute_input":"2025-04-05T11:03:09.261611Z","iopub.status.idle":"2025-04-05T11:03:09.266522Z","shell.execute_reply.started":"2025-04-05T11:03:09.261574Z","shell.execute_reply":"2025-04-05T11:03:09.265663Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Defining FusedImageDataset class","metadata":{}},{"cell_type":"code","source":"class FusedImageDataset(Dataset):\n    def __init__(self, dataframe, image_folder, transform=None):\n        self.dataframe = dataframe\n        self.image_folder = image_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = self.dataframe.iloc[idx]['fused_image_name']\n        \n        if not img_name.endswith('.png'):\n            img_name += '.png'\n        \n        label = self.dataframe.iloc[idx]['label']\n        img_path = os.path.join(self.image_folder, img_name)\n        \n        if not os.path.exists(img_path):\n            raise FileNotFoundError(f\"Image file {img_path} does not exist.\")\n        \n        image = Image.open(img_path).convert(\"RGB\")\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:03:09.267525Z","iopub.execute_input":"2025-04-05T11:03:09.267857Z","iopub.status.idle":"2025-04-05T11:03:09.281272Z","shell.execute_reply.started":"2025-04-05T11:03:09.267826Z","shell.execute_reply":"2025-04-05T11:03:09.280441Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Creating dataset and dataloader","metadata":{}},{"cell_type":"code","source":"image_folder = '/kaggle/working/fused_images_kaggle'  \n\ndataset = FusedImageDataset(data_df, image_folder, transform=transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:03:09.282118Z","iopub.execute_input":"2025-04-05T11:03:09.282376Z","iopub.status.idle":"2025-04-05T11:03:09.297391Z","shell.execute_reply.started":"2025-04-05T11:03:09.282357Z","shell.execute_reply":"2025-04-05T11:03:09.296751Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"1032"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"**Multiple transformations and fusing**","metadata":{}},{"cell_type":"code","source":"# Updated Transform Function for DICOM (Grayscale)\ntransform_dicom = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.Grayscale(num_output_channels=3),  \n    transforms.RandomHorizontalFlip(p=0.5),  \n    transforms.RandomRotation(degrees=15),  \n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  \n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n])\n\n# Updated Transform Function for Heatmaps (Already RGB)\ntransform_heatmap = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:06:39.130902Z","iopub.execute_input":"2025-04-05T11:06:39.131242Z","iopub.status.idle":"2025-04-05T11:06:39.137349Z","shell.execute_reply.started":"2025-04-05T11:06:39.131211Z","shell.execute_reply":"2025-04-05T11:06:39.136419Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Function to convert DICOM to a PIL Image","metadata":{}},{"cell_type":"code","source":"def dicom_to_pil(dicom_path):\n    dicom = pydicom.dcmread(dicom_path)\n    \n    image = dicom.pixel_array\n    image = (image - np.min(image)) / (np.max(image) - np.min(image)) * 255.0\n    image = image.astype(np.uint8)\n    \n    return Image.fromarray(image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:06:41.963326Z","iopub.execute_input":"2025-04-05T11:06:41.963645Z","iopub.status.idle":"2025-04-05T11:06:41.967992Z","shell.execute_reply.started":"2025-04-05T11:06:41.963583Z","shell.execute_reply":"2025-04-05T11:06:41.967173Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"Function to save multiple augmented fused images","metadata":{}},{"cell_type":"code","source":"def save_multiple_augmented_fused_images(dicom_folder, heatmap_folder, save_folder, num_augmentations=5):\n    if not os.path.exists(save_folder):\n        os.makedirs(save_folder)\n\n    for dicom_file in os.listdir(dicom_folder):\n        dicom_id = os.path.splitext(dicom_file)[0]  \n        \n        dicom_path = os.path.join(dicom_folder, dicom_file)\n        heatmap_path = os.path.join(heatmap_folder, dicom_id + \".png\")  \n\n        dicom_image = dicom_to_pil(dicom_path)\n        heatmap_image = Image.open(heatmap_path).convert(\"RGB\")\n\n        for i in range(num_augmentations):\n            dicom_image_transformed = transform_dicom(dicom_image)  \n            heatmap_image_transformed = transform_heatmap(heatmap_image)\n\n            fused_image = dicom_image_transformed * heatmap_image_transformed\n            fused_image = fused_image.permute(1, 2, 0).numpy()  \n            fused_image = (fused_image * 255).astype(np.uint8)  \n\n            fused_image_pil = Image.fromarray(fused_image)\n\n            save_path = os.path.join(save_folder, f\"{dicom_id}_{i + 1}.png\")  \n\n            fused_image_pil.save(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:06:43.966363Z","iopub.execute_input":"2025-04-05T11:06:43.966695Z","iopub.status.idle":"2025-04-05T11:06:43.972438Z","shell.execute_reply.started":"2025-04-05T11:06:43.966663Z","shell.execute_reply":"2025-04-05T11:06:43.971557Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"dicom_folder = '/kaggle/input/dicom-files/dicom files'  \nheatmap_folder = '/kaggle/input/heatmap-images/heatmap_images'  \nsave_folder = '/kaggle/working/multiple_aug_fused'  \n\nsave_multiple_augmented_fused_images(dicom_folder, heatmap_folder, save_folder, num_augmentations=15)","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:06:44.228501Z","iopub.execute_input":"2025-04-05T11:06:44.228767Z","iopub.status.idle":"2025-04-05T11:27:08.011813Z","shell.execute_reply.started":"2025-04-05T11:06:44.228745Z","shell.execute_reply":"2025-04-05T11:27:08.010878Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"**Updating the csv file**","metadata":{}},{"cell_type":"code","source":"augmented_dir = '/kaggle/working/multiple_aug_fused'  \ncsv_file = '/kaggle/input/labels-large/manually_made_large.csv'  \naug_csv_file = '/kaggle/working/aug_csv_file.csv'  \ndf = pd.read_csv(csv_file)\n\naugmented_image_names = [os.path.splitext(f)[0] for f in os.listdir(augmented_dir) if f.endswith('.png')]\naugmented_rows = []\n\nfor aug_img_name in augmented_image_names:\n    original_dicom_id = \"_\".join(aug_img_name.split(\"_\")[:-1])  \n\n    if original_dicom_id in df['fused_image_name'].values:\n        original_rows = df[df['fused_image_name'] == original_dicom_id]\n\n        for index, original_row in original_rows.iterrows():\n            new_row = {\n                'fused_image_name': aug_img_name,\n                'label': original_row['label']  \n            }\n            augmented_rows.append(new_row)\n\ndf_augmented = pd.DataFrame(augmented_rows)\ndf_updated = pd.concat([df, df_augmented], ignore_index=True)\ndf_updated.to_csv(aug_csv_file, index=False)\n\nprint(f\"Updated CSV file with augmented images saved at: {aug_csv_file}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:27:08.012952Z","iopub.execute_input":"2025-04-05T11:27:08.013259Z","iopub.status.idle":"2025-04-05T11:27:15.617055Z","shell.execute_reply.started":"2025-04-05T11:27:08.013229Z","shell.execute_reply":"2025-04-05T11:27:15.616316Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Updated CSV file with augmented images saved at: /kaggle/working/aug_csv_file.csv\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**adding both original and transformed to new folder**","metadata":{}},{"cell_type":"code","source":"original_fused_dir = '/kaggle/working/fused_images_kaggle'  \naugmented_fused_dir = '/kaggle/working/multiple_aug_fused'  \n\noriginal_images = [f for f in os.listdir(original_fused_dir) if os.path.isfile(os.path.join(original_fused_dir, f))]\n\ncounter = 0\n\nfor img in original_images:\n    img_id = os.path.splitext(img)[0]\n    new_img_name = f\"{img_id}_0.png\" \n    \n    src_path = os.path.join(original_fused_dir, img)\n    dest_path = os.path.join(augmented_fused_dir, new_img_name)\n    shutil.copy(src_path, dest_path)\n    \n    counter += 1\n\nprint(f\"Successfully added {counter} original fused images (without transformations) to the directory.\")","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:27:15.618365Z","iopub.execute_input":"2025-04-05T11:27:15.618607Z","iopub.status.idle":"2025-04-05T11:27:16.479428Z","shell.execute_reply.started":"2025-04-05T11:27:15.618571Z","shell.execute_reply":"2025-04-05T11:27:16.478705Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Successfully added 1032 original fused images (without transformations) to the directory.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"untransformed_ids = set(f'dicom_id_{i}' for i in range(1, 6)) \n\ndf_filtered = df_updated[~df_updated['fused_image_name'].apply(lambda x: os.path.basename(x) in untransformed_ids)]\n\ndf_filtered.to_csv('updated_original_dataset.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:27:16.480338Z","iopub.execute_input":"2025-04-05T11:27:16.480613Z","iopub.status.idle":"2025-04-05T11:27:16.520808Z","shell.execute_reply.started":"2025-04-05T11:27:16.480570Z","shell.execute_reply":"2025-04-05T11:27:16.520192Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"image_dir = '/kaggle/working/multiple_aug_fused'\ncsv_file_path = '/kaggle/working/aug_csv_file.csv'\nupdated_csv_path = 'updated_original_dataset_2.csv'\n\ndf = pd.read_csv(csv_file_path)\n\nfor filename in os.listdir(image_dir):\n    if filename.startswith('dicom_id') and filename.count('_') == 0:  \n        file_path = os.path.join(image_dir, filename)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted: {filename}\")\n\nremaining_images = set(os.listdir(image_dir))\n\ndf_filtered = df[~df['fused_image_name'].isin(remaining_images)]\n\ndf_filtered.to_csv(updated_csv_path, index=False)\n\nprint(f\"Removed entries from the CSV. Updated CSV saved as '{updated_csv_path}'.\")","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:27:16.521631Z","iopub.execute_input":"2025-04-05T11:27:16.521920Z","iopub.status.idle":"2025-04-05T11:27:16.591860Z","shell.execute_reply.started":"2025-04-05T11:27:16.521888Z","shell.execute_reply":"2025-04-05T11:27:16.591157Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Removed entries from the CSV. Updated CSV saved as 'updated_original_dataset_2.csv'.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import os\nimport pandas as pd\n\ncsv_file = '/kaggle/working/updated_original_dataset_2.csv'  \nimage_folder = '/kaggle/working/multiple_aug_fused'  \n\ndf = pd.read_csv(csv_file)\n\ncsv_row_count = len(df)\nprint(f\"Number of entries in the CSV file: {csv_row_count}\")\n\nimage_count = len([f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))])\nprint(f\"Number of images in the image folder: {image_count}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:27:16.592565Z","iopub.execute_input":"2025-04-05T11:27:16.592860Z","iopub.status.idle":"2025-04-05T11:27:16.713322Z","shell.execute_reply.started":"2025-04-05T11:27:16.592836Z","shell.execute_reply":"2025-04-05T11:27:16.712665Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of entries in the CSV file: 16512\nNumber of images in the image folder: 16512\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model = timm.create_model(\"vit_base_patch16_224\", pretrained=False, num_classes=3)\n\nweights_path = \"/kaggle/input/vit_model_w_more_aug/tensorflow1/default/1/final_model_20250331_135231.pth\" \nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n\nmodel.eval()\n\nprint(\"Model loaded\")","metadata":{"execution":{"iopub.status.busy":"2025-04-05T11:29:03.344171Z","iopub.execute_input":"2025-04-05T11:29:03.344466Z","iopub.status.idle":"2025-04-05T11:29:07.554752Z","shell.execute_reply.started":"2025-04-05T11:29:03.344434Z","shell.execute_reply":"2025-04-05T11:29:07.554016Z"},"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-21-1dcc14b1ac93>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"name":"stdout","text":"Model loaded\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"**CBMs**","metadata":{}},{"cell_type":"code","source":"concepts_csv = '/kaggle/input/final-concepts-latest/FINAL_CONCEPT(latest).csv'\nimage_dir = '/kaggle/working/multiple_aug_fused'\ncheckpoint_path = '/kaggle/input/vit_model_w_more_aug/tensorflow1/default/1/final_model_20250331_135231.pth'\nlog_file = 'lil_overfitting_log_file.txt'  # Log file name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:29:46.855522Z","iopub.execute_input":"2025-04-05T11:29:46.855848Z","iopub.status.idle":"2025-04-05T11:29:46.859653Z","shell.execute_reply.started":"2025-04-05T11:29:46.855822Z","shell.execute_reply":"2025-04-05T11:29:46.858697Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"with open(log_file, 'w') as f:\n    f.write(f\"Training Log - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    f.write(\"=\"*50 + \"\\n\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:29:48.628895Z","iopub.execute_input":"2025-04-05T11:29:48.629171Z","iopub.status.idle":"2025-04-05T11:29:48.633406Z","shell.execute_reply.started":"2025-04-05T11:29:48.629151Z","shell.execute_reply":"2025-04-05T11:29:48.632685Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"concepts_df = pd.read_csv(concepts_csv)\n\nif 'sid' in concepts_df.columns:\n    concepts_df = concepts_df.drop(columns=['sid'])\n\nlabel_columns = ['normal', 'pneumonia', 'chf']\ndef combine_labels(row):\n    for idx, col in enumerate(label_columns):\n        if row[col] == 1:\n            return idx\n    return -1\n\nconcepts_df['label'] = concepts_df.apply(combine_labels, axis=1)\nconcepts_df = concepts_df.drop(columns=label_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:29:52.090438Z","iopub.execute_input":"2025-04-05T11:29:52.090756Z","iopub.status.idle":"2025-04-05T11:29:52.181343Z","shell.execute_reply.started":"2025-04-05T11:29:52.090728Z","shell.execute_reply":"2025-04-05T11:29:52.180658Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def is_text_column(series, col):\n    if col in ['id', 'label']:\n        return False\n    return series.apply(lambda x: isinstance(x, str)).any()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:29:54.555823Z","iopub.execute_input":"2025-04-05T11:29:54.556106Z","iopub.status.idle":"2025-04-05T11:29:54.560199Z","shell.execute_reply.started":"2025-04-05T11:29:54.556085Z","shell.execute_reply":"2025-04-05T11:29:54.559270Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"text_columns = [col for col in concepts_df.columns if is_text_column(concepts_df[col], col)]\nconcepts_df = concepts_df.drop(columns=text_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:29:56.158906Z","iopub.execute_input":"2025-04-05T11:29:56.159187Z","iopub.status.idle":"2025-04-05T11:29:56.295235Z","shell.execute_reply.started":"2025-04-05T11:29:56.159164Z","shell.execute_reply":"2025-04-05T11:29:56.294613Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"all_images = os.listdir(image_dir)\ndef get_base_id(filename):\n    return filename.rsplit('_', 1)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:29:57.863997Z","iopub.execute_input":"2025-04-05T11:29:57.864272Z","iopub.status.idle":"2025-04-05T11:29:57.879216Z","shell.execute_reply.started":"2025-04-05T11:29:57.864249Z","shell.execute_reply":"2025-04-05T11:29:57.878383Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"available_base_ids = set(get_base_id(f) for f in all_images)\ninitial_concept_count = len(concepts_df)\nconcepts_df = concepts_df[concepts_df['id'].isin(available_base_ids)]\nfiltered_concept_count = len(concepts_df)\n\nprint(f\"Initial number of entries in concepts file: {initial_concept_count}\")\nprint(f\"Number of entries after filtering missing images: {filtered_concept_count}\")\nprint(f\"Number of images in the directory: {len(all_images)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:29:59.245924Z","iopub.execute_input":"2025-04-05T11:29:59.246196Z","iopub.status.idle":"2025-04-05T11:29:59.258358Z","shell.execute_reply.started":"2025-04-05T11:29:59.246174Z","shell.execute_reply":"2025-04-05T11:29:59.257627Z"}},"outputs":[{"name":"stdout","text":"Initial number of entries in concepts file: 1072\nNumber of entries after filtering missing images: 1027\nNumber of images in the directory: 16512\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"augmented_data = []\nfor _, row in concepts_df.iterrows():\n    base_id = row['id']\n    for suffix in range(1, 11):\n        augmented_id = f\"{base_id}_{suffix}\"\n        if any(img.startswith(augmented_id) for img in all_images) and augmented_id not in concepts_df['id'].values:\n            augmented_row = row.copy()\n            augmented_row['id'] = augmented_id\n            augmented_data.append(augmented_row)\n\nif augmented_data:\n    augmented_df = pd.DataFrame(augmented_data)\n    concepts_df = pd.concat([concepts_df, augmented_df], ignore_index=True)\n\nconcept_columns = [col for col in concepts_df.columns if col not in ['id', 'label']]\nnum_concepts = len(concept_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:30:04.761766Z","iopub.execute_input":"2025-04-05T11:30:04.762051Z","iopub.status.idle":"2025-04-05T11:30:16.911462Z","shell.execute_reply.started":"2025-04-05T11:30:04.762028Z","shell.execute_reply":"2025-04-05T11:30:16.910582Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"class StrongAugment:\n    def __call__(self, img):\n        transform = transforms.Compose([\n            transforms.RandomRotation(30),\n            transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n            transforms.GaussianBlur(3),\n            transforms.ToTensor()\n        ])\n        return transform(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:30:24.211010Z","iopub.execute_input":"2025-04-05T11:30:24.211319Z","iopub.status.idle":"2025-04-05T11:30:24.215751Z","shell.execute_reply.started":"2025-04-05T11:30:24.211293Z","shell.execute_reply":"2025-04-05T11:30:24.214851Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class ImageConceptDataset(Dataset):\n    def __init__(self, dataframe, image_dir):\n        self.dataframe = dataframe\n        self.image_dir = image_dir\n        self.standard_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n        ])\n        self.strong_transform = StrongAugment()\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        base_id = row['id']\n        label = row['label']\n\n        found_image = None\n        for suffix in range(10):\n            image_path = os.path.join(self.image_dir, f\"{base_id}_{suffix}.png\")\n            if os.path.exists(image_path):\n                found_image = image_path\n                break\n\n        if found_image is None:\n            return None\n\n        image = Image.open(found_image).convert('RGB')\n        image = self.strong_transform(image) if label == 1 else self.standard_transform(image)\n        concepts = row[concept_columns].values.astype(np.float32)\n\n        return image, torch.tensor(concepts), torch.tensor(label, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:30:26.987009Z","iopub.execute_input":"2025-04-05T11:30:26.987290Z","iopub.status.idle":"2025-04-05T11:30:26.993548Z","shell.execute_reply.started":"2025-04-05T11:30:26.987268Z","shell.execute_reply":"2025-04-05T11:30:26.992695Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"train_df, val_df = train_test_split(concepts_df, test_size=0.5, stratify=concepts_df['label'], random_state=42)\ntrain_dataset = [item for item in ImageConceptDataset(train_df, image_dir) if item is not None]\nval_dataset = [item for item in ImageConceptDataset(val_df, image_dir) if item is not None]\n\nlabels = np.array([label.item() for _, _, label in train_dataset])\nclass_counts = np.bincount(labels)\nclass_weights = 1.0 / np.sqrt(class_counts)\nsample_weights = class_weights[labels]\n\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(labels), replacement=True)\ntrain_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:30:29.444067Z","iopub.execute_input":"2025-04-05T11:30:29.444349Z","iopub.status.idle":"2025-04-05T11:32:28.480998Z","shell.execute_reply.started":"2025-04-05T11:30:29.444327Z","shell.execute_reply":"2025-04-05T11:32:28.480129Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_classes = len(label_columns)\n\nclass ViTWithConcepts(nn.Module):\n    def __init__(self, num_concepts, num_classes):\n        super(ViTWithConcepts, self).__init__()\n        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n        hidden_dim = self.vit.head.in_features\n        self.vit.head = nn.Identity()\n        self.concept_head = nn.Sequential(\n            nn.Linear(hidden_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_concepts)\n        )\n        self.prediction_head = nn.Sequential(\n            nn.Linear(num_concepts, 64),\n            nn.ReLU(),\n            nn.Linear(64, num_classes)\n        )\n\n    def forward(self, x):\n        features = self.vit(x)\n        concepts = self.concept_head(features)\n        logits = self.prediction_head(concepts)\n        return concepts, logits\n\nmodel = ViTWithConcepts(num_concepts, num_classes).to(device)\nconcept_criterion = nn.CrossEntropyLoss()\nclassification_criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:32:28.482132Z","iopub.execute_input":"2025-04-05T11:32:28.482426Z","iopub.status.idle":"2025-04-05T11:32:31.771519Z","shell.execute_reply.started":"2025-04-05T11:32:28.482390Z","shell.execute_reply":"2025-04-05T11:32:31.770785Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c9b49dd9494ed9a87db3ff5bc0dd6b"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, num_epochs=30):\n    with open(log_file, 'a') as f:\n        f.write(f\"Training started with {num_epochs} epochs\\n\")\n        f.write(f\"Model architecture: {str(model)}\\n\")\n        f.write(f\"Optimizer: {str(optimizer)}\\n\\n\")\n        \n        for epoch in range(num_epochs):\n            # Training phase\n            model.train()\n            running_loss = 0.0\n            correct, total = 0, 0\n            all_preds = []\n            all_labels = []\n            \n            # Initialize counters for class-wise accuracy\n            class_correct = [0] * num_classes\n            class_total = [0] * num_classes\n            \n            for images, true_concepts, labels in train_loader:\n                images, true_concepts, labels = images.to(device), true_concepts.to(device), labels.to(device)\n                optimizer.zero_grad()\n                predicted_concepts, class_logits = model(images)\n                loss = 0.8 * concept_criterion(predicted_concepts, true_concepts) + 0.2 * classification_criterion(class_logits, labels)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n                \n                _, preds = torch.max(class_logits, 1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n                \n                # Calculate class-wise correct predictions\n                for i in range(num_classes):\n                    class_mask = (labels == i)\n                    class_correct[i] += (preds[class_mask] == labels[class_mask]).sum().item()\n                    class_total[i] += class_mask.sum().item()\n            \n            # Calculate training metrics\n            train_acc = correct / total\n            train_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n            train_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n            train_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n            \n            # Calculate class-wise training accuracy\n            train_class_acc = []\n            for i in range(num_classes):\n                if class_total[i] > 0:\n                    train_class_acc.append(class_correct[i] / class_total[i])\n                else:\n                    train_class_acc.append(0.0)\n            \n            # Validation phase\n            model.eval()\n            val_correct, val_total = 0, 0\n            val_preds = []\n            val_labels = []\n            \n            # Initialize counters for class-wise validation accuracy\n            val_class_correct = [0] * num_classes\n            val_class_total = [0] * num_classes\n            \n            with torch.no_grad():\n                for images, _, labels in val_loader:\n                    images, labels = images.to(device), labels.to(device)\n                    _, class_logits = model(images)\n                    _, preds = torch.max(class_logits, 1)\n                    val_correct += (preds == labels).sum().item()\n                    val_total += labels.size(0)\n                    val_preds.extend(preds.cpu().numpy())\n                    val_labels.extend(labels.cpu().numpy())\n                    \n                    # Calculate class-wise correct predictions for validation\n                    for i in range(num_classes):\n                        class_mask = (labels == i)\n                        val_class_correct[i] += (preds[class_mask] == labels[class_mask]).sum().item()\n                        val_class_total[i] += class_mask.sum().item()\n            \n            # Calculate validation metrics\n            val_acc = val_correct / val_total\n            val_precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n            val_recall = recall_score(val_labels, val_preds, average='weighted', zero_division=0)\n            val_f1 = f1_score(val_labels, val_preds, average='weighted', zero_division=0)\n            \n            # Calculate class-wise validation accuracy\n            val_class_acc = []\n            for i in range(num_classes):\n                if val_class_total[i] > 0:\n                    val_class_acc.append(val_class_correct[i] / val_class_total[i])\n                else:\n                    val_class_acc.append(0.0)\n            \n            f.write(f\"\\nEpoch {epoch + 1}/{num_epochs}\\n\")\n            f.write(\"-\"*30 + \"\\n\")\n            f.write(f\"Training Loss: {running_loss:.4f}\\n\")\n            f.write(f\"Training Accuracy: {train_acc:.4f}\\n\")\n            f.write(f\"Training Precision: {train_precision:.4f}\\n\")\n            f.write(f\"Training Recall: {train_recall:.4f}\\n\")\n            f.write(f\"Training F1 Score: {train_f1:.4f}\\n\")\n            \n            f.write(\"\\nTraining Class-wise Accuracy:\\n\")\n            for i, class_name in enumerate(label_columns):\n                f.write(f\"{class_name}: {train_class_acc[i]:.4f} ({class_correct[i]}/{class_total[i]})\\n\")\n            \n            f.write(\"\\nValidation Metrics:\\n\")\n            f.write(f\"Validation Accuracy: {val_acc:.4f}\\n\")\n            f.write(f\"Validation Precision: {val_precision:.4f}\\n\")\n            f.write(f\"Validation Recall: {val_recall:.4f}\\n\")\n            f.write(f\"Validation F1 Score: {val_f1:.4f}\\n\")\n            \n            f.write(\"\\nValidation Class-wise Accuracy:\\n\")\n            for i, class_name in enumerate(label_columns):\n                f.write(f\"{class_name}: {val_class_acc[i]:.4f} ({val_class_correct[i]}/{val_class_total[i]})\\n\")\n            \n            f.write(\"-\"*50 + \"\\n\")\n            \n            # Also print to console\n            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n            print(f\"Training Loss: {running_loss:.4f}\")\n            print(f\"Training Accuracy: {train_acc:.4f} | Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1: {train_f1:.4f}\")\n            \n            print(\"\\nTraining Class-wise Accuracy:\")\n            for i, class_name in enumerate(label_columns):\n                print(f\"{class_name}: {train_class_acc[i]:.4f} ({class_correct[i]}/{class_total[i]})\")\n            \n            print(\"\\nValidation Metrics:\")\n            print(f\"Validation Accuracy: {val_acc:.4f} | Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}\")\n            \n            print(\"\\nValidation Class-wise Accuracy:\")\n            for i, class_name in enumerate(label_columns):\n                print(f\"{class_name}: {val_class_acc[i]:.4f} ({val_class_correct[i]}/{val_class_total[i]})\")\n            \n    # Final summary\n    with open(log_file, 'a') as f:\n        f.write(\"\\nTraining completed!\\n\")\n\n        print(classification_report(val_labels, val_preds))\n\n        cm = confusion_matrix(val_labels, val_preds)\n        plt.figure(figsize=(10, 7))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                    xticklabels=label_columns, yticklabels=label_columns)\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n        cm_filename = f'confusion_matrix_epoch_{epoch+1}.png'\n        plt.savefig(cm_filename)\n        plt.close()\n        \n        f.write(f\"\\nLog file and confusion matrices saved in current directory.\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:32:31.773156Z","iopub.execute_input":"2025-04-05T11:32:31.773502Z","iopub.status.idle":"2025-04-05T11:32:31.791822Z","shell.execute_reply.started":"2025-04-05T11:32:31.773473Z","shell.execute_reply":"2025-04-05T11:32:31.790937Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"train_model(model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:32:31.792725Z","iopub.execute_input":"2025-04-05T11:32:31.793013Z","iopub.status.idle":"2025-04-05T11:46:21.086080Z","shell.execute_reply.started":"2025-04-05T11:32:31.792977Z","shell.execute_reply":"2025-04-05T11:46:21.085273Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/30\nTraining Loss: 1364.5747\nTraining Accuracy: 0.3740 | Precision: 0.3481 | Recall: 0.3740 | F1: 0.2701\n\nTraining Class-wise Accuracy:\nnormal: 0.0964 (16/166)\npneumonia: 0.0390 (6/154)\nchf: 0.8724 (171/196)\n\nValidation Metrics:\nValidation Accuracy: 0.3131 | Precision: 0.2158 | Recall: 0.3131 | F1: 0.2455\n\nValidation Class-wise Accuracy:\nnormal: 0.0000 (0/170)\npneumonia: 0.3171 (52/164)\nchf: 0.6102 (108/177)\n\nEpoch 2/30\nTraining Loss: 1162.1786\nTraining Accuracy: 0.3081 | Precision: 0.2869 | Recall: 0.3081 | F1: 0.2702\n\nTraining Class-wise Accuracy:\nnormal: 0.0497 (9/181)\npneumonia: 0.4583 (77/168)\nchf: 0.4371 (73/167)\n\nValidation Metrics:\nValidation Accuracy: 0.3699 | Precision: 0.3374 | Recall: 0.3699 | F1: 0.3060\n\nValidation Class-wise Accuracy:\nnormal: 0.2588 (44/170)\npneumonia: 0.8110 (133/164)\nchf: 0.0678 (12/177)\n\nEpoch 3/30\nTraining Loss: 1077.0252\nTraining Accuracy: 0.3992 | Precision: 0.3793 | Recall: 0.3992 | F1: 0.3788\n\nTraining Class-wise Accuracy:\nnormal: 0.5055 (92/182)\npneumonia: 0.5333 (88/165)\nchf: 0.1538 (26/169)\n\nValidation Metrics:\nValidation Accuracy: 0.5127 | Precision: 0.5199 | Recall: 0.5127 | F1: 0.4691\n\nValidation Class-wise Accuracy:\nnormal: 0.6294 (107/170)\npneumonia: 0.7866 (129/164)\nchf: 0.1469 (26/177)\n\nEpoch 4/30\nTraining Loss: 1029.7455\nTraining Accuracy: 0.5969 | Precision: 0.6196 | Recall: 0.5969 | F1: 0.5847\n\nTraining Class-wise Accuracy:\nnormal: 0.7429 (130/175)\npneumonia: 0.7089 (112/158)\nchf: 0.3607 (66/183)\n\nValidation Metrics:\nValidation Accuracy: 0.6047 | Precision: 0.6200 | Recall: 0.6047 | F1: 0.5895\n\nValidation Class-wise Accuracy:\nnormal: 0.7471 (127/170)\npneumonia: 0.7317 (120/164)\nchf: 0.3503 (62/177)\n\nEpoch 5/30\nTraining Loss: 919.3781\nTraining Accuracy: 0.6550 | Precision: 0.6764 | Recall: 0.6550 | F1: 0.6484\n\nTraining Class-wise Accuracy:\nnormal: 0.8693 (153/176)\npneumonia: 0.5466 (88/161)\nchf: 0.5419 (97/179)\n\nValidation Metrics:\nValidation Accuracy: 0.6536 | Precision: 0.6533 | Recall: 0.6536 | F1: 0.6522\n\nValidation Class-wise Accuracy:\nnormal: 0.7412 (126/170)\npneumonia: 0.6220 (102/164)\nchf: 0.5989 (106/177)\n\nEpoch 6/30\nTraining Loss: 857.6581\nTraining Accuracy: 0.7112 | Precision: 0.7299 | Recall: 0.7112 | F1: 0.7093\n\nTraining Class-wise Accuracy:\nnormal: 0.8831 (136/154)\npneumonia: 0.6395 (110/172)\nchf: 0.6368 (121/190)\n\nValidation Metrics:\nValidation Accuracy: 0.6928 | Precision: 0.6932 | Recall: 0.6928 | F1: 0.6927\n\nValidation Class-wise Accuracy:\nnormal: 0.7176 (122/170)\npneumonia: 0.6707 (110/164)\nchf: 0.6893 (122/177)\n\nEpoch 7/30\nTraining Loss: 804.8901\nTraining Accuracy: 0.7229 | Precision: 0.7302 | Recall: 0.7229 | F1: 0.7203\n\nTraining Class-wise Accuracy:\nnormal: 0.8679 (138/159)\npneumonia: 0.6816 (122/179)\nchf: 0.6348 (113/178)\n\nValidation Metrics:\nValidation Accuracy: 0.7084 | Precision: 0.7120 | Recall: 0.7084 | F1: 0.7083\n\nValidation Class-wise Accuracy:\nnormal: 0.6588 (112/170)\npneumonia: 0.7134 (117/164)\nchf: 0.7514 (133/177)\n\nEpoch 8/30\nTraining Loss: 717.4880\nTraining Accuracy: 0.7616 | Precision: 0.7606 | Recall: 0.7616 | F1: 0.7574\n\nTraining Class-wise Accuracy:\nnormal: 0.9016 (165/183)\npneumonia: 0.6250 (105/168)\nchf: 0.7455 (123/165)\n\nValidation Metrics:\nValidation Accuracy: 0.7241 | Precision: 0.7298 | Recall: 0.7241 | F1: 0.7242\n\nValidation Class-wise Accuracy:\nnormal: 0.7706 (131/170)\npneumonia: 0.6707 (110/164)\nchf: 0.7288 (129/177)\n\nEpoch 9/30\nTraining Loss: 650.4886\nTraining Accuracy: 0.7519 | Precision: 0.7574 | Recall: 0.7519 | F1: 0.7443\n\nTraining Class-wise Accuracy:\nnormal: 0.8596 (153/178)\npneumonia: 0.5235 (78/149)\nchf: 0.8307 (157/189)\n\nValidation Metrics:\nValidation Accuracy: 0.6771 | Precision: 0.7071 | Recall: 0.6771 | F1: 0.6725\n\nValidation Class-wise Accuracy:\nnormal: 0.6941 (118/170)\npneumonia: 0.5000 (82/164)\nchf: 0.8249 (146/177)\n\nEpoch 10/30\nTraining Loss: 652.4224\nTraining Accuracy: 0.7539 | Precision: 0.7579 | Recall: 0.7539 | F1: 0.7501\n\nTraining Class-wise Accuracy:\nnormal: 0.8352 (152/182)\npneumonia: 0.5962 (93/156)\nchf: 0.8090 (144/178)\n\nValidation Metrics:\nValidation Accuracy: 0.7495 | Precision: 0.7670 | Recall: 0.7495 | F1: 0.7497\n\nValidation Class-wise Accuracy:\nnormal: 0.7824 (133/170)\npneumonia: 0.6463 (106/164)\nchf: 0.8136 (144/177)\n\nEpoch 11/30\nTraining Loss: 614.9655\nTraining Accuracy: 0.7752 | Precision: 0.7888 | Recall: 0.7752 | F1: 0.7718\n\nTraining Class-wise Accuracy:\nnormal: 0.8674 (157/181)\npneumonia: 0.6074 (99/163)\nchf: 0.8372 (144/172)\n\nValidation Metrics:\nValidation Accuracy: 0.7378 | Precision: 0.7414 | Recall: 0.7378 | F1: 0.7380\n\nValidation Class-wise Accuracy:\nnormal: 0.7412 (126/170)\npneumonia: 0.6951 (114/164)\nchf: 0.7740 (137/177)\n\nEpoch 12/30\nTraining Loss: 588.8103\nTraining Accuracy: 0.8159 | Precision: 0.8158 | Recall: 0.8159 | F1: 0.8131\n\nTraining Class-wise Accuracy:\nnormal: 0.8978 (167/186)\npneumonia: 0.6623 (100/151)\nchf: 0.8603 (154/179)\n\nValidation Metrics:\nValidation Accuracy: 0.7436 | Precision: 0.7672 | Recall: 0.7436 | F1: 0.7435\n\nValidation Class-wise Accuracy:\nnormal: 0.7824 (133/170)\npneumonia: 0.6220 (102/164)\nchf: 0.8192 (145/177)\n\nEpoch 13/30\nTraining Loss: 566.5815\nTraining Accuracy: 0.7771 | Precision: 0.7863 | Recall: 0.7771 | F1: 0.7771\n\nTraining Class-wise Accuracy:\nnormal: 0.8253 (137/166)\npneumonia: 0.6952 (130/187)\nchf: 0.8221 (134/163)\n\nValidation Metrics:\nValidation Accuracy: 0.7534 | Precision: 0.7546 | Recall: 0.7534 | F1: 0.7534\n\nValidation Class-wise Accuracy:\nnormal: 0.7118 (121/170)\npneumonia: 0.7744 (127/164)\nchf: 0.7740 (137/177)\n\nEpoch 14/30\nTraining Loss: 571.8081\nTraining Accuracy: 0.8217 | Precision: 0.8260 | Recall: 0.8217 | F1: 0.8207\n\nTraining Class-wise Accuracy:\nnormal: 0.8725 (130/149)\npneumonia: 0.7318 (131/179)\nchf: 0.8670 (163/188)\n\nValidation Metrics:\nValidation Accuracy: 0.7515 | Precision: 0.7744 | Recall: 0.7515 | F1: 0.7530\n\nValidation Class-wise Accuracy:\nnormal: 0.6824 (116/170)\npneumonia: 0.7073 (116/164)\nchf: 0.8588 (152/177)\n\nEpoch 15/30\nTraining Loss: 560.3196\nTraining Accuracy: 0.8081 | Precision: 0.8133 | Recall: 0.8081 | F1: 0.8071\n\nTraining Class-wise Accuracy:\nnormal: 0.8140 (140/172)\npneumonia: 0.7091 (117/165)\nchf: 0.8939 (160/179)\n\nValidation Metrics:\nValidation Accuracy: 0.7613 | Precision: 0.7758 | Recall: 0.7613 | F1: 0.7626\n\nValidation Class-wise Accuracy:\nnormal: 0.7235 (123/170)\npneumonia: 0.7195 (118/164)\nchf: 0.8362 (148/177)\n\nEpoch 16/30\nTraining Loss: 561.6884\nTraining Accuracy: 0.8624 | Precision: 0.8635 | Recall: 0.8624 | F1: 0.8623\n\nTraining Class-wise Accuracy:\nnormal: 0.8854 (139/157)\npneumonia: 0.8261 (152/184)\nchf: 0.8800 (154/175)\n\nValidation Metrics:\nValidation Accuracy: 0.7476 | Precision: 0.7764 | Recall: 0.7476 | F1: 0.7488\n\nValidation Class-wise Accuracy:\nnormal: 0.6882 (117/170)\npneumonia: 0.6707 (110/164)\nchf: 0.8757 (155/177)\n\nEpoch 17/30\nTraining Loss: 518.4436\nTraining Accuracy: 0.8508 | Precision: 0.8539 | Recall: 0.8508 | F1: 0.8510\n\nTraining Class-wise Accuracy:\nnormal: 0.8478 (156/184)\npneumonia: 0.8058 (112/139)\nchf: 0.8860 (171/193)\n\nValidation Metrics:\nValidation Accuracy: 0.7515 | Precision: 0.7872 | Recall: 0.7515 | F1: 0.7531\n\nValidation Class-wise Accuracy:\nnormal: 0.7765 (132/170)\npneumonia: 0.6280 (103/164)\nchf: 0.8418 (149/177)\n\nEpoch 18/30\nTraining Loss: 546.3959\nTraining Accuracy: 0.8488 | Precision: 0.8618 | Recall: 0.8488 | F1: 0.8478\n\nTraining Class-wise Accuracy:\nnormal: 0.8786 (152/173)\npneumonia: 0.7107 (113/159)\nchf: 0.9402 (173/184)\n\nValidation Metrics:\nValidation Accuracy: 0.7710 | Precision: 0.7847 | Recall: 0.7710 | F1: 0.7723\n\nValidation Class-wise Accuracy:\nnormal: 0.8471 (144/170)\npneumonia: 0.7256 (119/164)\nchf: 0.7401 (131/177)\n\nEpoch 19/30\nTraining Loss: 518.6060\nTraining Accuracy: 0.8605 | Precision: 0.8638 | Recall: 0.8605 | F1: 0.8602\n\nTraining Class-wise Accuracy:\nnormal: 0.9000 (162/180)\npneumonia: 0.7895 (120/152)\nchf: 0.8804 (162/184)\n\nValidation Metrics:\nValidation Accuracy: 0.7730 | Precision: 0.7837 | Recall: 0.7730 | F1: 0.7743\n\nValidation Class-wise Accuracy:\nnormal: 0.8235 (140/170)\npneumonia: 0.7317 (120/164)\nchf: 0.7627 (135/177)\n\nEpoch 20/30\nTraining Loss: 516.5144\nTraining Accuracy: 0.8779 | Precision: 0.8815 | Recall: 0.8779 | F1: 0.8773\n\nTraining Class-wise Accuracy:\nnormal: 0.9077 (177/195)\npneumonia: 0.7815 (118/151)\nchf: 0.9294 (158/170)\n\nValidation Metrics:\nValidation Accuracy: 0.7808 | Precision: 0.7961 | Recall: 0.7808 | F1: 0.7834\n\nValidation Class-wise Accuracy:\nnormal: 0.7588 (129/170)\npneumonia: 0.7561 (124/164)\nchf: 0.8249 (146/177)\n\nEpoch 21/30\nTraining Loss: 520.8213\nTraining Accuracy: 0.8740 | Precision: 0.8787 | Recall: 0.8740 | F1: 0.8745\n\nTraining Class-wise Accuracy:\nnormal: 0.8708 (155/178)\npneumonia: 0.8352 (152/182)\nchf: 0.9231 (144/156)\n\nValidation Metrics:\nValidation Accuracy: 0.7906 | Precision: 0.8049 | Recall: 0.7906 | F1: 0.7928\n\nValidation Class-wise Accuracy:\nnormal: 0.8000 (136/170)\npneumonia: 0.7500 (123/164)\nchf: 0.8192 (145/177)\n\nEpoch 22/30\nTraining Loss: 528.3061\nTraining Accuracy: 0.8663 | Precision: 0.8686 | Recall: 0.8663 | F1: 0.8662\n\nTraining Class-wise Accuracy:\nnormal: 0.8765 (142/162)\npneumonia: 0.8176 (130/159)\nchf: 0.8974 (175/195)\n\nValidation Metrics:\nValidation Accuracy: 0.7710 | Precision: 0.8029 | Recall: 0.7710 | F1: 0.7740\n\nValidation Class-wise Accuracy:\nnormal: 0.7706 (131/170)\npneumonia: 0.6829 (112/164)\nchf: 0.8531 (151/177)\n\nEpoch 23/30\nTraining Loss: 527.0788\nTraining Accuracy: 0.9128 | Precision: 0.9156 | Recall: 0.9128 | F1: 0.9132\n\nTraining Class-wise Accuracy:\nnormal: 0.9123 (156/171)\npneumonia: 0.8896 (145/163)\nchf: 0.9341 (170/182)\n\nValidation Metrics:\nValidation Accuracy: 0.8004 | Precision: 0.8128 | Recall: 0.8004 | F1: 0.8031\n\nValidation Class-wise Accuracy:\nnormal: 0.7941 (135/170)\npneumonia: 0.7927 (130/164)\nchf: 0.8136 (144/177)\n\nEpoch 24/30\nTraining Loss: 485.7700\nTraining Accuracy: 0.9089 | Precision: 0.9117 | Recall: 0.9089 | F1: 0.9095\n\nTraining Class-wise Accuracy:\nnormal: 0.8950 (162/181)\npneumonia: 0.9102 (152/167)\nchf: 0.9226 (155/168)\n\nValidation Metrics:\nValidation Accuracy: 0.8043 | Precision: 0.8164 | Recall: 0.8043 | F1: 0.8069\n\nValidation Class-wise Accuracy:\nnormal: 0.8000 (136/170)\npneumonia: 0.7927 (130/164)\nchf: 0.8192 (145/177)\n\nEpoch 25/30\nTraining Loss: 505.3500\nTraining Accuracy: 0.9109 | Precision: 0.9160 | Recall: 0.9109 | F1: 0.9115\n\nTraining Class-wise Accuracy:\nnormal: 0.9326 (166/178)\npneumonia: 0.8706 (148/170)\nchf: 0.9286 (156/168)\n\nValidation Metrics:\nValidation Accuracy: 0.8043 | Precision: 0.8106 | Recall: 0.8043 | F1: 0.8059\n\nValidation Class-wise Accuracy:\nnormal: 0.7824 (133/170)\npneumonia: 0.8171 (134/164)\nchf: 0.8136 (144/177)\n\nEpoch 26/30\nTraining Loss: 494.7397\nTraining Accuracy: 0.8973 | Precision: 0.8997 | Recall: 0.8973 | F1: 0.8977\n\nTraining Class-wise Accuracy:\nnormal: 0.8743 (160/183)\npneumonia: 0.9006 (145/161)\nchf: 0.9186 (158/172)\n\nValidation Metrics:\nValidation Accuracy: 0.7926 | Precision: 0.8109 | Recall: 0.7926 | F1: 0.7943\n\nValidation Class-wise Accuracy:\nnormal: 0.8882 (151/170)\npneumonia: 0.7622 (125/164)\nchf: 0.7288 (129/177)\n\nEpoch 27/30\nTraining Loss: 484.8937\nTraining Accuracy: 0.9264 | Precision: 0.9283 | Recall: 0.9264 | F1: 0.9261\n\nTraining Class-wise Accuracy:\nnormal: 0.9769 (169/173)\npneumonia: 0.8802 (147/167)\nchf: 0.9205 (162/176)\n\nValidation Metrics:\nValidation Accuracy: 0.8141 | Precision: 0.8203 | Recall: 0.8141 | F1: 0.8157\n\nValidation Class-wise Accuracy:\nnormal: 0.8176 (139/170)\npneumonia: 0.8232 (135/164)\nchf: 0.8023 (142/177)\n\nEpoch 28/30\nTraining Loss: 506.9231\nTraining Accuracy: 0.9341 | Precision: 0.9351 | Recall: 0.9341 | F1: 0.9342\n\nTraining Class-wise Accuracy:\nnormal: 0.9270 (165/178)\npneumonia: 0.9226 (143/155)\nchf: 0.9508 (174/183)\n\nValidation Metrics:\nValidation Accuracy: 0.7691 | Precision: 0.7975 | Recall: 0.7691 | F1: 0.7715\n\nValidation Class-wise Accuracy:\nnormal: 0.8000 (136/170)\npneumonia: 0.6768 (111/164)\nchf: 0.8249 (146/177)\n\nEpoch 29/30\nTraining Loss: 514.4967\nTraining Accuracy: 0.9167 | Precision: 0.9220 | Recall: 0.9167 | F1: 0.9173\n\nTraining Class-wise Accuracy:\nnormal: 0.9048 (152/168)\npneumonia: 0.8876 (150/169)\nchf: 0.9553 (171/179)\n\nValidation Metrics:\nValidation Accuracy: 0.8004 | Precision: 0.8108 | Recall: 0.8004 | F1: 0.8028\n\nValidation Class-wise Accuracy:\nnormal: 0.8176 (139/170)\npneumonia: 0.7988 (131/164)\nchf: 0.7853 (139/177)\n\nEpoch 30/30\nTraining Loss: 523.0174\nTraining Accuracy: 0.9457 | Precision: 0.9462 | Recall: 0.9457 | F1: 0.9459\n\nTraining Class-wise Accuracy:\nnormal: 0.9438 (168/178)\npneumonia: 0.9477 (163/172)\nchf: 0.9458 (157/166)\n\nValidation Metrics:\nValidation Accuracy: 0.8219 | Precision: 0.8237 | Recall: 0.8219 | F1: 0.8226\n\nValidation Class-wise Accuracy:\nnormal: 0.8118 (138/170)\npneumonia: 0.8720 (143/164)\nchf: 0.7853 (139/177)\n              precision    recall  f1-score   support\n\n           0       0.80      0.81      0.80       170\n           1       0.91      0.87      0.89       164\n           2       0.77      0.79      0.78       177\n\n    accuracy                           0.82       511\n   macro avg       0.83      0.82      0.82       511\nweighted avg       0.82      0.82      0.82       511\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}